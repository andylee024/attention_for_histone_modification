{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from komorebi.libs.model.attention_configuration import AttentionConfiguration\n",
    "from komorebi.libs.model.attention_model import AttentionModel \n",
    "from komorebi.libs.dataset.dataset_config import DatasetConfiguration\n",
    "from komorebi.libs.model.parameter_initialization import ParameterInitializationPolicy\n",
    "from komorebi.libs.optimizer.optimizer_config import OptimizerConfiguration\n",
    "from komorebi.libs.optimizer.optimizer_factory import create_tf_optimizer \n",
    "from komorebi.libs.trainer.attention_trainer import AttentionTrainer\n",
    "from komorebi.libs.trainer.trainer_config import TrainerConfiguration\n",
    "from komorebi.libs.utilities.io_utils import copy_data, ensure_directory, load_pickle_object, remove_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow specific directories\n",
    "CHECKPOINT_DIRECTORY_NAME = \"model_checkpoints\"\n",
    "CONFIG_DIRECTORY_NAME = \"config\"\n",
    "SUMMARY_DIRECTORY_NAME = \"training_summaries\"\n",
    "\n",
    "ExperimentConfiguration = collections.namedtuple(typename='ExperimentConfiguration', \n",
    "                                                 field_names=['experiment_directory',\n",
    "                                                              'checkpoint_directory',\n",
    "                                                              'config_directory',\n",
    "                                                              'summary_directory',\n",
    "                                                              'dataset_config', \n",
    "                                                              'model_config', \n",
    "                                                              'trainer_config', \n",
    "                                                              'optimizer_config', \n",
    "                                                              'parameter_initialization'])\n",
    "\n",
    "def _parse_experiment_config_json(experiment_config_json):\n",
    "    \"\"\"Parse experiment json and convert to experiment config.\n",
    "\n",
    "    Parse relevant fields in experiment configuration file. \n",
    "\n",
    "    :param config_json: path to experiment config json.\n",
    "    :return: \n",
    "        ExperimentConfiguration named-tuple with the following attributes.\n",
    "            experiment_name      : name of experiment\n",
    "            experiment_directory : base directory to create experiment directory \n",
    "            dataset_config              : dataset configuration object\n",
    "            model_config                : model configuration object\n",
    "            trainer_config              : trainer configuration object\n",
    "            optimizer_config            : optimizer configuration object\n",
    "    \"\"\"\n",
    "    with open(experiment_config_json, 'r') as f:\n",
    "        experiment_info = json.load(f)\n",
    "\n",
    "        experiment_directory = os.path.join(experiment_info['experiments_directory'], \n",
    "                                            experiment_info['experiment_name'])\n",
    "        checkpoint_directory = os.path.join(experiment_directory, CHECKPOINT_DIRECTORY_NAME)\n",
    "        config_directory = os.path.join(experiment_directory, CONFIG_DIRECTORY_NAME)\n",
    "        summary_directory = os.path.join(experiment_directory, SUMMARY_DIRECTORY_NAME)\n",
    "        \n",
    "        return ExperimentConfiguration(experiment_directory=experiment_directory,\n",
    "                                       checkpoint_directory=checkpoint_directory,\n",
    "                                       config_directory=config_directory,\n",
    "                                       summary_directory=summary_directory,\n",
    "                                       parameter_initialization=ParameterInitializationPolicy(),\n",
    "                                       dataset_config=_create_dataset_configuration(experiment_info['dataset_config']),\n",
    "                                       model_config=_create_model_configuration(experiment_info['model_config']),\n",
    "                                       trainer_config=_create_trainer_configuration(experiment_info['trainer_config']),\n",
    "                                       optimizer_config=_create_optimizer_configuration(experiment_info['trainer_config']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/andy/Projects/biology/research/komorebi/data/attention_validation_dataset/sharded_attention_dataset.pkl\"\n",
    "dataset = load_pickle_object(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "dataset_times = []\n",
    "for _ in range(10):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    dataset.get_training_examples(range(8000))\n",
    "    t1 = time.time()\n",
    "    dataset_times.append(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.861739897727965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset_times)/len(dataset_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Profiling Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "a = tf.random_normal([2000, 5000])\n",
    "b = tf.random_normal([5000, 1000])\n",
    "res = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # add additional options to trace the session execution\n",
    "    options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    sess.run(res, options=options, run_metadata=run_metadata)\n",
    "\n",
    "    # Create the Timeline object, and write it to a json file\n",
    "    fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n",
    "    chrome_trace = fetched_timeline.generate_chrome_trace_format()\n",
    "    with open('timeline_01.json', 'w') as f:\n",
    "        f.write(chrome_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
