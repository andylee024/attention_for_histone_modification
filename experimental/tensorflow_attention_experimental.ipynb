{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Attention Experimental\n",
    "This notebook provides a rough implementation of the attention model for histone modification prediction in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "In this section, we list out the important hyperparameters used in our prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction parameters\n",
    "\n",
    "N = 100  # batch size\n",
    "L = 196  # number of annotation vectors per training example\n",
    "D = 500  # dimension of each annotation vector\n",
    "H = 100  # number of hidden units\n",
    "T = 400  # length of sequence\n",
    "V = 4    # vocabulary size ('a', 'c', 'g', 't')\n",
    "C = 3    # number of prediction classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "In this section, we create dummy data for one batch on which we run our prediction. This is primarily to test that the pipeline runs correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilities for converting tensors to one_hot\n",
    "\n",
    "def convert_label_to_one_hot(label, number_of_classes):\n",
    "    \"\"\"Converts a label to one hot encoding\"\"\"\n",
    "    one_hot_encoding = np.zeros(number_of_classes)\n",
    "    one_hot_encoding[label] = 1\n",
    "    return np.reshape(one_hot_encoding, newshape=(1, number_of_classes))\n",
    "\n",
    "def convert_to_one_hot(labels, number_of_classes):\n",
    "    \"\"\"Convert a list of labels to one hot encoding.\"\"\"\n",
    "    one_hot_labels = [convert_label_to_one_hot(l, number_of_classes=number_of_classes) for l in labels]\n",
    "    return np.concatenate(one_hot_labels, axis=0)\n",
    "\n",
    "def convert_training_examples_to_tensor(training_examples):\n",
    "    \"\"\"Convert batch data to tensor representation.\n",
    "    \n",
    "    @param training_examples:\n",
    "        List of training examples.\n",
    "    @return: \n",
    "        Numpy tensors of dimension (N x (A1 x A2)), where N is batch dimension and (A1 x A2) is dimension of \n",
    "        matrix corresponding to training example\n",
    "    \"\"\"\n",
    "    # Add batch dimension to tensors and concatenate matrices across batch dimension\n",
    "    sequence_tensor = np.concatenate([np.expand_dims(te.sequence, axis=0) for te in training_examples], axis=0)\n",
    "    annotation_tensor = np.concatenate([np.expand_dims(te.annotation_vectors, axis=0) for te in training_examples], axis=0)\n",
    "    label_tensor = np.concatenate([np.expand_dims(te.label, axis=0) for te in training_examples], axis=0)\n",
    "    \n",
    "    return TrainingTensor(sequence_tensor=sequence_tensor, \n",
    "                          annotation_tensor=annotation_tensor, \n",
    "                          label_tensor=label_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "TrainingExample = collections.namedtuple(\n",
    "    typename='TrainingExample', field_names=['sequence', 'annotation_vectors', 'label'])\n",
    "\n",
    "TrainingTensor = collections.namedtuple(\n",
    "    typename=\"TrainingTensor\", field_names=['sequence_tensor', 'annotation_tensor', 'label_tensor'])\n",
    "\n",
    "def create_dummy_training_example():\n",
    "    \"\"\"Create a single training example with dummy data.\"\"\"\n",
    "    dummy_sequence = convert_to_one_hot(labels=np.random.randint(low=0, high=V, size=T), number_of_classes=V)\n",
    "    dummy_label = convert_label_to_one_hot(label=np.random.randint(low=0, high=3, size=1), number_of_classes=C)\n",
    "    dummy_annotation_vectors = np.random.normal(loc=0.0, scale=1.0, size=(L, D))\n",
    "    \n",
    "    return TrainingExample(sequence=dummy_sequence,\n",
    "                           annotation_vectors=dummy_annotation_vectors,\n",
    "                           label=dummy_label)    \n",
    "\n",
    "def create_dummy_batch_data():\n",
    "    \"\"\"Create training examples for batch.\"\"\"\n",
    "    training_examples = [create_dummy_training_example() for _ in xrange(N)]\n",
    "    return convert_training_examples_to_tensor(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_data = create_dummy_batch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400, 4)\n",
      "(100, 196, 500)\n",
      "(100, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print batch_data.sequence_tensor.shape\n",
    "print batch_data.annotation_tensor.shape\n",
    "print batch_data.label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
