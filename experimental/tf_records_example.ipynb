{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Records example\n",
    "This notebook contains scratch code for creating a single tf.record from an existing training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from komorebi.libs.utilities.io_utils import load_pickle_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load single training example\n",
    "We load a single training example data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence shape: (1000, 4)\n",
      "label shape: (919,)\n",
      "annotation shape: (75, 320)\n"
     ]
    }
   ],
   "source": [
    "sharded_dataset_path = \"/Users/andy/Projects/biology/research/komorebi/data/attention_validation_dataset/sharded_attention_dataset.pkl\"\n",
    "dataset = load_pickle_object(sharded_dataset_path)\n",
    "training_examples = dataset.get_training_examples(range(2))\n",
    "te = training_examples[0]\n",
    "\n",
    "sequence_shape = te.sequence.shape\n",
    "label_shape = te.label.shape\n",
    "annotation_shape = te.annotation.shape\n",
    "\n",
    "print \"sequence shape: {}\".format(sequence_shape)\n",
    "print \"label shape: {}\".format(label_shape)\n",
    "print \"annotation shape: {}\".format(annotation_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert training example to tf record.\n",
    "Prototype code to convert training example to tf record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for writing tf example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEQUENCE_SHAPE = (1000, 4)\n",
    "ANNOTATION_SHAPE = (75, 320)\n",
    "TF_SINGLE_RECORD_PATH = \"/tmp/training_example_0.tfrecords\"\n",
    "\n",
    "# define feature translation functions\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to_tf_example(training_example):\n",
    "    \"\"\"Convert training example type to tf example.\n",
    "    \n",
    "    For some reason, the features keyword argument needs to be present in Features() object.\n",
    "    \"\"\"\n",
    "    return tf.train.Example(features=tf.train.Features(\n",
    "        feature={\n",
    "            'sequence_raw': _bytes_feature(training_example.sequence.tostring()),\n",
    "            'label_raw': _bytes_feature(training_example.label.tostring()),\n",
    "            'annotation_raw': _bytes_feature(training_example.annotation.tostring())}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write TF example to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert training example to tf record\n",
    "tf_example = convert_to_tf_example(training_examples[0])\n",
    "\n",
    "# write tf_example to disk\n",
    "writer = tf.python_io.TFRecordWriter(TF_SINGLE_RECORD_PATH)\n",
    "writer.write(tf_example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for reading tf example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_example(tf_example):\n",
    "    \"\"\"Parse tensorflow example\"\"\"\n",
    "    \n",
    "    features_map = {\n",
    "        'sequence_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'annotation_raw': tf.FixedLenFeature([], tf.string)}\n",
    "    \n",
    "    parsed_example = tf.parse_single_example(serialized_example, features_map)\n",
    "    \n",
    "    sequence_raw = tf.decode_raw(parsed_example['sequence_raw'], tf.uint8)\n",
    "    annotation_raw = tf.decode_raw(parsed_example['annotation_raw'], tf.float32)\n",
    "    \n",
    "    sequence = tf.reshape(sequence_raw, SEQUENCE_SHAPE)\n",
    "    label = tf.decode_raw(parsed_example['label_raw'], tf.uint8)\n",
    "    annotation = tf.reshape(annotation_raw, ANNOTATION_SHAPE)\n",
    "    \n",
    "    return {'sequence': sequence, 'label': label, 'annotation': annotation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Read tf example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TF_RECORD = \"/tmp/attention_valiation_tf_records/example_1001.tfrecord\"\n",
    "record_iterator = tf.python_io.tf_record_iterator(TF_RECORD)\n",
    "serialized_example = record_iterator.next()\n",
    "feed_dict = parse_example(serialized_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "decoded_sequence = feed_dict['sequence'].eval()\n",
    "decoded_annotation = feed_dict['annotation'].eval()\n",
    "decoded_label = feed_dict['label'].eval()  \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "(75, 320)\n",
      "(919,)\n"
     ]
    }
   ],
   "source": [
    "# Validate tensors deserialized correctly\n",
    "print decoded_sequence.shape\n",
    "print decoded_annotation.shape\n",
    "print decoded_label.shape\n",
    "\n",
    "#print np.array_equal(decoded_sequence, te.sequence)\n",
    "#print np.array_equal(decoded_label, te.label)\n",
    "#print np.array_equal(decoded_annotation, te.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create validation dataset in tf records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TF_VALIDATION_DATASET = \"/tmp/validation_dataset.tfrecord\"\n",
    "training_examples = dataset.get_training_examples(range(8000))\n",
    "\n",
    "# convert to training examples to tf examples\n",
    "tf_examples = [convert_to_tf_example(te) for te in training_examples]\n",
    "\n",
    "# write to disk\n",
    "writer = tf.python_io.TFRecordWriter(TF_VALIDATION_DATASET)\n",
    "for tf_example in tf_examples:    \n",
    "    writer.write(tf_example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deserialize dataset\n",
    "filenames = [TF_VALIDATION_DATASET]\n",
    "tf_dataset = tf.data.TFRecordDataset(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_dataset = tf_dataset.map(parse_example, num_threads=6, output_buffer_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = tf_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "(919,)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sequence = next_element['sequence'].eval()\n",
    "label = next_element['label'].eval()\n",
    "\n",
    "print sequence.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batched_dataset = tf_dataset.batch(100)\n",
    "batched_iter = batched_dataset.make_one_shot_iterator()\n",
    "batched_next = batched_iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1000, 4)\n",
      "(100, 75, 320)\n",
      "(100, 919)\n"
     ]
    }
   ],
   "source": [
    "b_element = batched_next\n",
    "b_sequence = b_element['sequence']\n",
    "b_annotation = b_element['annotation']\n",
    "b_label = b_element['label']\n",
    "\n",
    "print b_sequence.eval().shape\n",
    "print b_annotation.eval().shape\n",
    "print b_label.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
